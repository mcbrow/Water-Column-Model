21/10/14 23:42:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/10/14 23:42:09 INFO SecurityManager: Changing view acls to: michael
21/10/14 23:42:09 INFO SecurityManager: Changing modify acls to: michael
21/10/14 23:42:09 INFO SecurityManager: Changing view acls groups to: 
21/10/14 23:42:09 INFO SecurityManager: Changing modify acls groups to: 
21/10/14 23:42:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(michael); groups with view permissions: Set(); users  with modify permissions: Set(michael); groups with modify permissions: Set()
21/10/14 23:42:09 INFO HiveConf: Found configuration file file:/Users/michael/spark/spark-3.1.1-bin-hadoop3.2/conf/hive-site.xml
21/10/14 23:42:10 INFO SparkContext: Running Spark version 3.1.1
21/10/14 23:42:10 INFO ResourceUtils: ==============================================================
21/10/14 23:42:10 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/14 23:42:10 INFO ResourceUtils: ==============================================================
21/10/14 23:42:10 INFO SparkContext: Submitted application: sparklyr
21/10/14 23:42:10 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/14 23:42:10 INFO ResourceProfile: Limiting resource is cpu
21/10/14 23:42:10 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/14 23:42:10 INFO SecurityManager: Changing view acls to: michael
21/10/14 23:42:10 INFO SecurityManager: Changing modify acls to: michael
21/10/14 23:42:10 INFO SecurityManager: Changing view acls groups to: 
21/10/14 23:42:10 INFO SecurityManager: Changing modify acls groups to: 
21/10/14 23:42:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(michael); groups with view permissions: Set(); users  with modify permissions: Set(michael); groups with modify permissions: Set()
21/10/14 23:42:10 INFO Utils: Successfully started service 'sparkDriver' on port 56382.
21/10/14 23:42:10 INFO SparkEnv: Registering MapOutputTracker
21/10/14 23:42:10 INFO SparkEnv: Registering BlockManagerMaster
21/10/14 23:42:10 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/14 23:42:10 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/14 23:42:10 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/14 23:42:10 INFO DiskBlockManager: Created local directory at /private/var/folders/p2/x6gbxz7n48q1mm1zbdjj1wkm0000gq/T/blockmgr-9571a624-e543-4570-978a-2bbc075a5c84
21/10/14 23:42:10 INFO MemoryStore: MemoryStore started with capacity 1048.8 MiB
21/10/14 23:42:10 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/14 23:42:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/14 23:42:10 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/10/14 23:42:10 INFO SparkContext: Added JAR file:/Users/michael/Library/Caches/org.R-project.R/R/renv/cache/v5/R-4.1/x86_64-apple-darwin17.0/sparklyr/1.7.2/c0631dd0f7a88495f55ef50d1ac89cc5/sparklyr/java/sparklyr-master-2.12.jar at spark://localhost:56382/jars/sparklyr-master-2.12.jar with timestamp 1634251330050
21/10/14 23:42:10 INFO Executor: Starting executor ID driver on host localhost
21/10/14 23:42:10 INFO Executor: Fetching spark://localhost:56382/jars/sparklyr-master-2.12.jar with timestamp 1634251330050
21/10/14 23:42:10 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:56382 after 16 ms (0 ms spent in bootstraps)
21/10/14 23:42:10 INFO Utils: Fetching spark://localhost:56382/jars/sparklyr-master-2.12.jar to /private/var/folders/p2/x6gbxz7n48q1mm1zbdjj1wkm0000gq/T/spark-4ab0623a-e4c2-4dd5-b067-566aeb1a1f5e/userFiles-eb7c1682-2166-4cda-a274-d6aaf5f2150f/fetchFileTemp14107332228954458156.tmp
21/10/14 23:42:10 INFO Executor: Adding file:/private/var/folders/p2/x6gbxz7n48q1mm1zbdjj1wkm0000gq/T/spark-4ab0623a-e4c2-4dd5-b067-566aeb1a1f5e/userFiles-eb7c1682-2166-4cda-a274-d6aaf5f2150f/sparklyr-master-2.12.jar to class loader
21/10/14 23:42:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56386.
21/10/14 23:42:10 INFO NettyBlockTransferService: Server created on localhost:56386
21/10/14 23:42:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/14 23:42:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 56386, None)
21/10/14 23:42:10 INFO BlockManagerMasterEndpoint: Registering block manager localhost:56386 with 1048.8 MiB RAM, BlockManagerId(driver, localhost, 56386, None)
21/10/14 23:42:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 56386, None)
21/10/14 23:42:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 56386, None)
21/10/14 23:42:11 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/michael/Desktop/PhD/Research%20Methods/Water%20Column%20Models/spark-warehouse').
21/10/14 23:42:11 INFO SharedState: Warehouse path is 'file:/Users/michael/Desktop/PhD/Research%20Methods/Water%20Column%20Models/spark-warehouse'.
21/10/14 23:42:13 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/10/14 23:42:14 INFO SessionState: Created HDFS directory: /tmp/hive/michael
21/10/14 23:42:14 INFO SessionState: Created local directory: /var/folders/p2/x6gbxz7n48q1mm1zbdjj1wkm0000gq/T/michael
21/10/14 23:42:14 INFO SessionState: Created HDFS directory: /tmp/hive/michael/78428025-dc41-4492-8245-c33af6c4e531
21/10/14 23:42:14 INFO SessionState: Created local directory: /var/folders/p2/x6gbxz7n48q1mm1zbdjj1wkm0000gq/T/michael/78428025-dc41-4492-8245-c33af6c4e531
21/10/14 23:42:14 INFO SessionState: Created HDFS directory: /tmp/hive/michael/78428025-dc41-4492-8245-c33af6c4e531/_tmp_space.db
21/10/14 23:42:14 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/michael/Desktop/PhD/Research%20Methods/Water%20Column%20Models/spark-warehouse
21/10/14 23:42:14 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/10/14 23:42:14 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/10/14 23:42:14 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/10/14 23:42:14 INFO ObjectStore: ObjectStore, initialize called
21/10/14 23:42:14 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/10/14 23:42:14 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/10/14 23:42:15 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/10/14 23:42:17 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/10/14 23:42:17 INFO ObjectStore: Initialized ObjectStore
21/10/14 23:42:17 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/10/14 23:42:17 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore michael@127.0.0.1
21/10/14 23:42:17 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/10/14 23:42:17 INFO HiveMetaStore: Added admin role in metastore
21/10/14 23:42:17 INFO HiveMetaStore: Added public role in metastore
21/10/14 23:42:17 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/10/14 23:42:17 INFO HiveMetaStore: 0: get_all_functions
21/10/14 23:42:17 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_all_functions	
21/10/14 23:42:17 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:42:17 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:42:17 INFO HiveMetaStore: 0: get_database: global_temp
21/10/14 23:42:17 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/10/14 23:42:17 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/10/14 23:42:17 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:42:17 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:42:17 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:42:17 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:42:17 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/10/14 23:42:17 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/10/14 23:42:18 INFO CodeGenerator: Code generated in 237.698222 ms
21/10/14 23:42:18 INFO CodeGenerator: Code generated in 13.92662 ms
21/10/14 23:42:19 INFO SparkContext: Starting job: count at utils.scala:24
21/10/14 23:42:19 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:24) as input to shuffle 0
21/10/14 23:42:19 INFO DAGScheduler: Got job 0 (count at utils.scala:24) with 1 output partitions
21/10/14 23:42:19 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:24)
21/10/14 23:42:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/10/14 23:42:19 INFO DAGScheduler: Missing parents: List()
21/10/14 23:42:19 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:24), which has no missing parents
21/10/14 23:42:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 1048.8 MiB)
21/10/14 23:42:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 1048.8 MiB)
21/10/14 23:42:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:56386 (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:42:19 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1383
21/10/14 23:42:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/14 23:42:19 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
21/10/14 23:42:19 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0) (localhost, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/10/14 23:42:19 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/10/14 23:42:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/10/14 23:42:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
21/10/14 23:42:19 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2641 bytes result sent to driver
21/10/14 23:42:19 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 156 ms on localhost (executor driver) (1/1)
21/10/14 23:42:19 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/10/14 23:42:19 INFO DAGScheduler: ResultStage 1 (count at utils.scala:24) finished in 0.392 s
21/10/14 23:42:19 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/10/14 23:42:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/10/14 23:42:19 INFO DAGScheduler: Job 0 finished: count at utils.scala:24, took 0.451070 s
21/10/14 23:42:19 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:42:19 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:42:19 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:42:19 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:42:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/10/14 23:42:19 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/10/14 23:42:19 INFO SparkContext: Starting job: count at utils.scala:24
21/10/14 23:42:19 INFO DAGScheduler: Registering RDD 8 (count at utils.scala:24) as input to shuffle 1
21/10/14 23:42:19 INFO DAGScheduler: Got job 1 (count at utils.scala:24) with 1 output partitions
21/10/14 23:42:19 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:24)
21/10/14 23:42:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/10/14 23:42:19 INFO DAGScheduler: Missing parents: List()
21/10/14 23:42:19 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:24), which has no missing parents
21/10/14 23:42:19 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KiB, free 1048.8 MiB)
21/10/14 23:42:19 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 1048.8 MiB)
21/10/14 23:42:19 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:56386 (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:42:19 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1383
21/10/14 23:42:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/14 23:42:19 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
21/10/14 23:42:19 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 1) (localhost, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/10/14 23:42:19 INFO Executor: Running task 0.0 in stage 3.0 (TID 1)
21/10/14 23:42:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/10/14 23:42:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/10/14 23:42:19 INFO Executor: Finished task 0.0 in stage 3.0 (TID 1). 2641 bytes result sent to driver
21/10/14 23:42:19 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 1) in 8 ms on localhost (executor driver) (1/1)
21/10/14 23:42:19 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/10/14 23:42:19 INFO DAGScheduler: ResultStage 3 (count at utils.scala:24) finished in 0.014 s
21/10/14 23:42:19 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/10/14 23:42:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/10/14 23:42:19 INFO DAGScheduler: Job 1 finished: count at utils.scala:24, took 0.016661 s
21/10/14 23:43:36 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:43:36 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:43:36 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:43:36 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:43:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/10/14 23:43:36 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/10/14 23:43:36 INFO SparkContext: Starting job: count at utils.scala:24
21/10/14 23:43:36 INFO DAGScheduler: Registering RDD 14 (count at utils.scala:24) as input to shuffle 2
21/10/14 23:43:36 INFO DAGScheduler: Got job 2 (count at utils.scala:24) with 1 output partitions
21/10/14 23:43:36 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:24)
21/10/14 23:43:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/10/14 23:43:36 INFO DAGScheduler: Missing parents: List()
21/10/14 23:43:36 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[17] at count at utils.scala:24), which has no missing parents
21/10/14 23:43:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.1 KiB, free 1048.8 MiB)
21/10/14 23:43:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 1048.8 MiB)
21/10/14 23:43:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:56386 (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:43:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1383
21/10/14 23:43:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/14 23:43:36 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
21/10/14 23:43:36 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 2) (localhost, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/10/14 23:43:36 INFO Executor: Running task 0.0 in stage 5.0 (TID 2)
21/10/14 23:43:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/10/14 23:43:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/10/14 23:43:36 INFO Executor: Finished task 0.0 in stage 5.0 (TID 2). 2641 bytes result sent to driver
21/10/14 23:43:36 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 2) in 9 ms on localhost (executor driver) (1/1)
21/10/14 23:43:36 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/10/14 23:43:36 INFO DAGScheduler: ResultStage 5 (count at utils.scala:24) finished in 0.019 s
21/10/14 23:43:36 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
21/10/14 23:43:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
21/10/14 23:43:36 INFO DAGScheduler: Job 2 finished: count at utils.scala:24, took 0.023088 s
21/10/14 23:43:54 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:43:54 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:43:54 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:43:54 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:43:54 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/10/14 23:43:54 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/10/14 23:43:54 INFO SparkContext: Starting job: count at utils.scala:24
21/10/14 23:43:54 INFO DAGScheduler: Registering RDD 21 (count at utils.scala:24) as input to shuffle 3
21/10/14 23:43:54 INFO DAGScheduler: Got job 3 (count at utils.scala:24) with 1 output partitions
21/10/14 23:43:54 INFO DAGScheduler: Final stage: ResultStage 7 (count at utils.scala:24)
21/10/14 23:43:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
21/10/14 23:43:54 INFO DAGScheduler: Missing parents: List()
21/10/14 23:43:54 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[24] at count at utils.scala:24), which has no missing parents
21/10/14 23:43:54 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 10.1 KiB, free 1048.7 MiB)
21/10/14 23:43:54 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 1048.7 MiB)
21/10/14 23:43:54 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:56386 (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:43:54 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1383
21/10/14 23:43:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[24] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/14 23:43:54 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
21/10/14 23:43:54 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 3) (localhost, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/10/14 23:43:54 INFO Executor: Running task 0.0 in stage 7.0 (TID 3)
21/10/14 23:43:54 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/10/14 23:43:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/10/14 23:43:54 INFO Executor: Finished task 0.0 in stage 7.0 (TID 3). 2641 bytes result sent to driver
21/10/14 23:43:54 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 3) in 6 ms on localhost (executor driver) (1/1)
21/10/14 23:43:54 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/10/14 23:43:54 INFO DAGScheduler: ResultStage 7 (count at utils.scala:24) finished in 0.010 s
21/10/14 23:43:54 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
21/10/14 23:43:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
21/10/14 23:43:54 INFO DAGScheduler: Job 3 finished: count at utils.scala:24, took 0.012726 s
21/10/14 23:44:49 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:44:49 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:44:49 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:44:49 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:44:49 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/10/14 23:44:49 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/10/14 23:44:49 INFO SparkContext: Starting job: count at utils.scala:24
21/10/14 23:44:49 INFO DAGScheduler: Registering RDD 28 (count at utils.scala:24) as input to shuffle 4
21/10/14 23:44:49 INFO DAGScheduler: Got job 4 (count at utils.scala:24) with 1 output partitions
21/10/14 23:44:49 INFO DAGScheduler: Final stage: ResultStage 9 (count at utils.scala:24)
21/10/14 23:44:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
21/10/14 23:44:49 INFO DAGScheduler: Missing parents: List()
21/10/14 23:44:49 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[31] at count at utils.scala:24), which has no missing parents
21/10/14 23:44:49 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.1 KiB, free 1048.7 MiB)
21/10/14 23:44:49 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 1048.7 MiB)
21/10/14 23:44:49 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:56386 (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:44:49 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1383
21/10/14 23:44:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[31] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/14 23:44:49 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
21/10/14 23:44:49 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 4) (localhost, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/10/14 23:44:49 INFO Executor: Running task 0.0 in stage 9.0 (TID 4)
21/10/14 23:44:49 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/10/14 23:44:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/10/14 23:44:49 INFO Executor: Finished task 0.0 in stage 9.0 (TID 4). 2641 bytes result sent to driver
21/10/14 23:44:49 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 4) in 5 ms on localhost (executor driver) (1/1)
21/10/14 23:44:49 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/10/14 23:44:49 INFO DAGScheduler: ResultStage 9 (count at utils.scala:24) finished in 0.011 s
21/10/14 23:44:49 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
21/10/14 23:44:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
21/10/14 23:44:49 INFO DAGScheduler: Job 4 finished: count at utils.scala:24, took 0.013743 s
21/10/14 23:46:11 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:46:11 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:46:11 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:46:11 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:46:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/10/14 23:46:11 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/10/14 23:46:11 INFO SparkContext: Starting job: count at utils.scala:24
21/10/14 23:46:11 INFO DAGScheduler: Registering RDD 35 (count at utils.scala:24) as input to shuffle 5
21/10/14 23:46:11 INFO DAGScheduler: Got job 5 (count at utils.scala:24) with 1 output partitions
21/10/14 23:46:11 INFO DAGScheduler: Final stage: ResultStage 11 (count at utils.scala:24)
21/10/14 23:46:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
21/10/14 23:46:11 INFO DAGScheduler: Missing parents: List()
21/10/14 23:46:11 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[38] at count at utils.scala:24), which has no missing parents
21/10/14 23:46:11 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.1 KiB, free 1048.7 MiB)
21/10/14 23:46:11 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 1048.7 MiB)
21/10/14 23:46:11 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:56386 (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:46:11 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1383
21/10/14 23:46:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[38] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/14 23:46:11 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
21/10/14 23:46:11 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 5) (localhost, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/10/14 23:46:11 INFO Executor: Running task 0.0 in stage 11.0 (TID 5)
21/10/14 23:46:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/10/14 23:46:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/10/14 23:46:11 INFO Executor: Finished task 0.0 in stage 11.0 (TID 5). 2641 bytes result sent to driver
21/10/14 23:46:11 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 5) in 7 ms on localhost (executor driver) (1/1)
21/10/14 23:46:11 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/10/14 23:46:11 INFO DAGScheduler: ResultStage 11 (count at utils.scala:24) finished in 0.013 s
21/10/14 23:46:11 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
21/10/14 23:46:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
21/10/14 23:46:11 INFO DAGScheduler: Job 5 finished: count at utils.scala:24, took 0.016256 s
21/10/14 23:46:11 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:56386 in memory (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:46:11 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:56386 in memory (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:46:11 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:56386 in memory (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:46:11 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:56386 in memory (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:46:11 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:56386 in memory (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:46:11 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:56386 in memory (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:46:19 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:46:19 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:46:19 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:46:19 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:46:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/10/14 23:46:19 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/10/14 23:46:19 INFO SparkContext: Starting job: count at utils.scala:24
21/10/14 23:46:19 INFO DAGScheduler: Registering RDD 42 (count at utils.scala:24) as input to shuffle 6
21/10/14 23:46:19 INFO DAGScheduler: Got job 6 (count at utils.scala:24) with 1 output partitions
21/10/14 23:46:19 INFO DAGScheduler: Final stage: ResultStage 13 (count at utils.scala:24)
21/10/14 23:46:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
21/10/14 23:46:19 INFO DAGScheduler: Missing parents: List()
21/10/14 23:46:19 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[45] at count at utils.scala:24), which has no missing parents
21/10/14 23:46:19 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 10.1 KiB, free 1048.8 MiB)
21/10/14 23:46:19 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 1048.8 MiB)
21/10/14 23:46:19 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:56386 (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:46:19 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1383
21/10/14 23:46:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[45] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/14 23:46:19 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
21/10/14 23:46:19 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 6) (localhost, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/10/14 23:46:19 INFO Executor: Running task 0.0 in stage 13.0 (TID 6)
21/10/14 23:46:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/10/14 23:46:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/10/14 23:46:19 INFO Executor: Finished task 0.0 in stage 13.0 (TID 6). 2641 bytes result sent to driver
21/10/14 23:46:19 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 6) in 6 ms on localhost (executor driver) (1/1)
21/10/14 23:46:19 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/10/14 23:46:19 INFO DAGScheduler: ResultStage 13 (count at utils.scala:24) finished in 0.011 s
21/10/14 23:46:19 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
21/10/14 23:46:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
21/10/14 23:46:19 INFO DAGScheduler: Job 6 finished: count at utils.scala:24, took 0.013292 s
21/10/14 23:46:23 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:46:23 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:46:23 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:46:23 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:46:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/10/14 23:46:23 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/10/14 23:46:23 INFO SparkContext: Starting job: count at utils.scala:24
21/10/14 23:46:23 INFO DAGScheduler: Registering RDD 49 (count at utils.scala:24) as input to shuffle 7
21/10/14 23:46:23 INFO DAGScheduler: Got job 7 (count at utils.scala:24) with 1 output partitions
21/10/14 23:46:23 INFO DAGScheduler: Final stage: ResultStage 15 (count at utils.scala:24)
21/10/14 23:46:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
21/10/14 23:46:23 INFO DAGScheduler: Missing parents: List()
21/10/14 23:46:23 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[52] at count at utils.scala:24), which has no missing parents
21/10/14 23:46:23 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 10.1 KiB, free 1048.8 MiB)
21/10/14 23:46:23 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 1048.8 MiB)
21/10/14 23:46:23 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:56386 (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:46:23 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1383
21/10/14 23:46:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[52] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/14 23:46:23 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
21/10/14 23:46:23 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 7) (localhost, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/10/14 23:46:23 INFO Executor: Running task 0.0 in stage 15.0 (TID 7)
21/10/14 23:46:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/10/14 23:46:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/10/14 23:46:23 INFO Executor: Finished task 0.0 in stage 15.0 (TID 7). 2641 bytes result sent to driver
21/10/14 23:46:23 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 7) in 6 ms on localhost (executor driver) (1/1)
21/10/14 23:46:23 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/10/14 23:46:23 INFO DAGScheduler: ResultStage 15 (count at utils.scala:24) finished in 0.012 s
21/10/14 23:46:23 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
21/10/14 23:46:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
21/10/14 23:46:23 INFO DAGScheduler: Job 7 finished: count at utils.scala:24, took 0.014225 s
21/10/14 23:46:45 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:46:45 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:46:45 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:46:45 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:46:45 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/10/14 23:46:45 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/10/14 23:46:45 INFO SparkContext: Starting job: count at utils.scala:24
21/10/14 23:46:45 INFO DAGScheduler: Registering RDD 56 (count at utils.scala:24) as input to shuffle 8
21/10/14 23:46:45 INFO DAGScheduler: Got job 8 (count at utils.scala:24) with 1 output partitions
21/10/14 23:46:45 INFO DAGScheduler: Final stage: ResultStage 17 (count at utils.scala:24)
21/10/14 23:46:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
21/10/14 23:46:45 INFO DAGScheduler: Missing parents: List()
21/10/14 23:46:45 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[59] at count at utils.scala:24), which has no missing parents
21/10/14 23:46:45 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 10.1 KiB, free 1048.8 MiB)
21/10/14 23:46:45 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 1048.8 MiB)
21/10/14 23:46:45 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:56386 (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:46:45 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1383
21/10/14 23:46:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[59] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/14 23:46:45 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
21/10/14 23:46:45 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 8) (localhost, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/10/14 23:46:45 INFO Executor: Running task 0.0 in stage 17.0 (TID 8)
21/10/14 23:46:45 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/10/14 23:46:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/10/14 23:46:45 INFO Executor: Finished task 0.0 in stage 17.0 (TID 8). 2641 bytes result sent to driver
21/10/14 23:46:45 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 8) in 5 ms on localhost (executor driver) (1/1)
21/10/14 23:46:45 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/10/14 23:46:45 INFO DAGScheduler: ResultStage 17 (count at utils.scala:24) finished in 0.011 s
21/10/14 23:46:45 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
21/10/14 23:46:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
21/10/14 23:46:45 INFO DAGScheduler: Job 8 finished: count at utils.scala:24, took 0.014448 s
21/10/14 23:47:23 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:47:23 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:47:23 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:47:23 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:47:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/10/14 23:47:23 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/10/14 23:47:23 INFO SparkContext: Starting job: count at utils.scala:24
21/10/14 23:47:23 INFO DAGScheduler: Registering RDD 63 (count at utils.scala:24) as input to shuffle 9
21/10/14 23:47:23 INFO DAGScheduler: Got job 9 (count at utils.scala:24) with 1 output partitions
21/10/14 23:47:23 INFO DAGScheduler: Final stage: ResultStage 19 (count at utils.scala:24)
21/10/14 23:47:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
21/10/14 23:47:23 INFO DAGScheduler: Missing parents: List()
21/10/14 23:47:23 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[66] at count at utils.scala:24), which has no missing parents
21/10/14 23:47:23 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 10.1 KiB, free 1048.7 MiB)
21/10/14 23:47:23 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 1048.7 MiB)
21/10/14 23:47:23 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:56386 (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:47:23 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1383
21/10/14 23:47:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[66] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/14 23:47:23 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
21/10/14 23:47:23 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 9) (localhost, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/10/14 23:47:23 INFO Executor: Running task 0.0 in stage 19.0 (TID 9)
21/10/14 23:47:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/10/14 23:47:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/10/14 23:47:23 INFO Executor: Finished task 0.0 in stage 19.0 (TID 9). 2641 bytes result sent to driver
21/10/14 23:47:23 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 9) in 6 ms on localhost (executor driver) (1/1)
21/10/14 23:47:23 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/10/14 23:47:23 INFO DAGScheduler: ResultStage 19 (count at utils.scala:24) finished in 0.011 s
21/10/14 23:47:23 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
21/10/14 23:47:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
21/10/14 23:47:23 INFO DAGScheduler: Job 9 finished: count at utils.scala:24, took 0.014055 s
21/10/14 23:47:23 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
21/10/14 23:47:24 INFO CodeGenerator: Code generated in 10.245497 ms
21/10/14 23:47:24 INFO SparkContext: Starting job: collect at utils.scala:26
21/10/14 23:47:24 INFO DAGScheduler: Got job 10 (collect at utils.scala:26) with 1 output partitions
21/10/14 23:47:24 INFO DAGScheduler: Final stage: ResultStage 20 (collect at utils.scala:26)
21/10/14 23:47:24 INFO DAGScheduler: Parents of final stage: List()
21/10/14 23:47:24 INFO DAGScheduler: Missing parents: List()
21/10/14 23:47:24 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[71] at collect at utils.scala:26), which has no missing parents
21/10/14 23:47:24 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 17.9 KiB, free 1048.7 MiB)
21/10/14 23:47:24 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 1048.7 MiB)
21/10/14 23:47:24 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:56386 (size: 5.5 KiB, free: 1048.8 MiB)
21/10/14 23:47:24 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1383
21/10/14 23:47:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[71] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
21/10/14 23:47:24 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
21/10/14 23:47:24 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 10) (localhost, executor driver, partition 0, PROCESS_LOCAL, 4689 bytes) taskResourceAssignments Map()
21/10/14 23:47:24 INFO Executor: Running task 0.0 in stage 20.0 (TID 10)
21/10/14 23:47:24 INFO CodeGenerator: Code generated in 36.77402 ms
21/10/14 23:47:24 INFO Executor: Finished task 0.0 in stage 20.0 (TID 10). 1401 bytes result sent to driver
21/10/14 23:47:24 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 10) in 79 ms on localhost (executor driver) (1/1)
21/10/14 23:47:24 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/10/14 23:47:24 INFO DAGScheduler: ResultStage 20 (collect at utils.scala:26) finished in 0.085 s
21/10/14 23:47:24 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
21/10/14 23:47:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
21/10/14 23:47:24 INFO DAGScheduler: Job 10 finished: collect at utils.scala:26, took 0.087162 s
21/10/14 23:47:24 INFO CodeGenerator: Code generated in 31.411056 ms
21/10/14 23:47:24 INFO CodeGenerator: Code generated in 6.658382 ms
21/10/14 23:47:24 INFO SparkContext: Starting job: count at utils.scala:24
21/10/14 23:47:24 INFO DAGScheduler: Registering RDD 73 (count at utils.scala:24) as input to shuffle 10
21/10/14 23:47:24 INFO DAGScheduler: Got job 11 (count at utils.scala:24) with 1 output partitions
21/10/14 23:47:24 INFO DAGScheduler: Final stage: ResultStage 22 (count at utils.scala:24)
21/10/14 23:47:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
21/10/14 23:47:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
21/10/14 23:47:24 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[73] at count at utils.scala:24), which has no missing parents
21/10/14 23:47:24 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 10.0 KiB, free 1048.7 MiB)
21/10/14 23:47:24 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 1048.7 MiB)
21/10/14 23:47:24 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:56386 (size: 5.2 KiB, free: 1048.8 MiB)
21/10/14 23:47:24 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1383
21/10/14 23:47:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[73] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/14 23:47:24 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
21/10/14 23:47:24 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 11) (localhost, executor driver, partition 0, PROCESS_LOCAL, 4678 bytes) taskResourceAssignments Map()
21/10/14 23:47:24 INFO Executor: Running task 0.0 in stage 21.0 (TID 11)
21/10/14 23:47:24 INFO Executor: Finished task 0.0 in stage 21.0 (TID 11). 1833 bytes result sent to driver
21/10/14 23:47:24 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 11) in 43 ms on localhost (executor driver) (1/1)
21/10/14 23:47:24 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/10/14 23:47:24 INFO DAGScheduler: ShuffleMapStage 21 (count at utils.scala:24) finished in 0.053 s
21/10/14 23:47:24 INFO DAGScheduler: looking for newly runnable stages
21/10/14 23:47:24 INFO DAGScheduler: running: Set()
21/10/14 23:47:24 INFO DAGScheduler: waiting: Set(ResultStage 22)
21/10/14 23:47:24 INFO DAGScheduler: failed: Set()
21/10/14 23:47:24 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[76] at count at utils.scala:24), which has no missing parents
21/10/14 23:47:24 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 10.1 KiB, free 1048.7 MiB)
21/10/14 23:47:24 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 1048.7 MiB)
21/10/14 23:47:24 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:56386 (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:47:24 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1383
21/10/14 23:47:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[76] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/14 23:47:24 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
21/10/14 23:47:24 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 12) (localhost, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/10/14 23:47:24 INFO Executor: Running task 0.0 in stage 22.0 (TID 12)
21/10/14 23:47:24 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/10/14 23:47:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
21/10/14 23:47:24 INFO Executor: Finished task 0.0 in stage 22.0 (TID 12). 2648 bytes result sent to driver
21/10/14 23:47:24 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 12) in 20 ms on localhost (executor driver) (1/1)
21/10/14 23:47:24 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/10/14 23:47:24 INFO DAGScheduler: ResultStage 22 (count at utils.scala:24) finished in 0.028 s
21/10/14 23:47:24 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
21/10/14 23:47:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
21/10/14 23:47:24 INFO DAGScheduler: Job 11 finished: count at utils.scala:24, took 0.094504 s
21/10/14 23:47:25 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:56386 in memory (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:47:25 INFO BlockManagerInfo: Removed broadcast_9_piece0 on localhost:56386 in memory (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:47:25 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:56386 in memory (size: 5.2 KiB, free: 1048.8 MiB)
21/10/14 23:47:25 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:56386 in memory (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:47:25 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:56386 in memory (size: 5.5 KiB, free: 1048.8 MiB)
21/10/14 23:47:25 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:56386 in memory (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:47:25 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:56386 in memory (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:47:25 INFO SparkContext: Starting job: collect at utils.scala:26
21/10/14 23:47:25 INFO DAGScheduler: Got job 12 (collect at utils.scala:26) with 1 output partitions
21/10/14 23:47:25 INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:26)
21/10/14 23:47:25 INFO DAGScheduler: Parents of final stage: List()
21/10/14 23:47:25 INFO DAGScheduler: Missing parents: List()
21/10/14 23:47:25 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[79] at collect at utils.scala:26), which has no missing parents
21/10/14 23:47:25 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 18.7 KiB, free 1048.8 MiB)
21/10/14 23:47:25 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 1048.8 MiB)
21/10/14 23:47:25 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:56386 (size: 5.9 KiB, free: 1048.8 MiB)
21/10/14 23:47:25 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1383
21/10/14 23:47:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[79] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
21/10/14 23:47:25 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0
21/10/14 23:47:25 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 13) (localhost, executor driver, partition 0, PROCESS_LOCAL, 4689 bytes) taskResourceAssignments Map()
21/10/14 23:47:25 INFO Executor: Running task 0.0 in stage 23.0 (TID 13)
21/10/14 23:47:25 INFO Executor: Finished task 0.0 in stage 23.0 (TID 13). 1401 bytes result sent to driver
21/10/14 23:47:25 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 13) in 17 ms on localhost (executor driver) (1/1)
21/10/14 23:47:25 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
21/10/14 23:47:25 INFO DAGScheduler: ResultStage 23 (collect at utils.scala:26) finished in 0.021 s
21/10/14 23:47:25 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
21/10/14 23:47:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
21/10/14 23:47:25 INFO DAGScheduler: Job 12 finished: collect at utils.scala:26, took 0.022437 s
21/10/14 23:47:25 INFO SparkContext: Starting job: count at utils.scala:24
21/10/14 23:47:25 INFO DAGScheduler: Registering RDD 81 (count at utils.scala:24) as input to shuffle 11
21/10/14 23:47:25 INFO DAGScheduler: Got job 13 (count at utils.scala:24) with 1 output partitions
21/10/14 23:47:25 INFO DAGScheduler: Final stage: ResultStage 25 (count at utils.scala:24)
21/10/14 23:47:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)
21/10/14 23:47:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 24)
21/10/14 23:47:25 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[81] at count at utils.scala:24), which has no missing parents
21/10/14 23:47:25 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 10.0 KiB, free 1048.8 MiB)
21/10/14 23:47:25 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 1048.8 MiB)
21/10/14 23:47:25 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:56386 (size: 5.2 KiB, free: 1048.8 MiB)
21/10/14 23:47:25 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1383
21/10/14 23:47:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[81] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/14 23:47:25 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
21/10/14 23:47:25 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 14) (localhost, executor driver, partition 0, PROCESS_LOCAL, 4678 bytes) taskResourceAssignments Map()
21/10/14 23:47:25 INFO Executor: Running task 0.0 in stage 24.0 (TID 14)
21/10/14 23:47:25 INFO Executor: Finished task 0.0 in stage 24.0 (TID 14). 1833 bytes result sent to driver
21/10/14 23:47:25 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 14) in 7 ms on localhost (executor driver) (1/1)
21/10/14 23:47:25 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
21/10/14 23:47:25 INFO DAGScheduler: ShuffleMapStage 24 (count at utils.scala:24) finished in 0.013 s
21/10/14 23:47:25 INFO DAGScheduler: looking for newly runnable stages
21/10/14 23:47:25 INFO DAGScheduler: running: Set()
21/10/14 23:47:25 INFO DAGScheduler: waiting: Set(ResultStage 25)
21/10/14 23:47:25 INFO DAGScheduler: failed: Set()
21/10/14 23:47:25 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[84] at count at utils.scala:24), which has no missing parents
21/10/14 23:47:25 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 10.1 KiB, free 1048.8 MiB)
21/10/14 23:47:25 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.1 KiB, free 1048.7 MiB)
21/10/14 23:47:25 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:56386 (size: 5.1 KiB, free: 1048.8 MiB)
21/10/14 23:47:25 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1383
21/10/14 23:47:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[84] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/14 23:47:25 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
21/10/14 23:47:25 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 15) (localhost, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/10/14 23:47:25 INFO Executor: Running task 0.0 in stage 25.0 (TID 15)
21/10/14 23:47:25 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/10/14 23:47:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/10/14 23:47:25 INFO Executor: Finished task 0.0 in stage 25.0 (TID 15). 2648 bytes result sent to driver
21/10/14 23:47:25 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 15) in 6 ms on localhost (executor driver) (1/1)
21/10/14 23:47:25 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
21/10/14 23:47:25 INFO DAGScheduler: ResultStage 25 (count at utils.scala:24) finished in 0.010 s
21/10/14 23:47:25 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
21/10/14 23:47:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
21/10/14 23:47:25 INFO DAGScheduler: Job 13 finished: count at utils.scala:24, took 0.026196 s
21/10/14 23:47:25 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:47:25 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:47:25 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:47:25 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:47:25 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/10/14 23:47:25 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/10/14 23:47:25 INFO CodeGenerator: Code generated in 6.092561 ms
21/10/14 23:47:25 INFO CodeGenerator: Code generated in 9.595157 ms
21/10/14 23:47:25 INFO CodeGenerator: Code generated in 5.080752 ms
21/10/14 23:47:25 INFO SparkContext: Starting job: count at utils.scala:24
21/10/14 23:47:25 INFO DAGScheduler: Registering RDD 87 (count at utils.scala:24) as input to shuffle 12
21/10/14 23:47:25 INFO DAGScheduler: Got job 14 (count at utils.scala:24) with 1 output partitions
21/10/14 23:47:25 INFO DAGScheduler: Final stage: ResultStage 27 (count at utils.scala:24)
21/10/14 23:47:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
21/10/14 23:47:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 26)
21/10/14 23:47:25 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[87] at count at utils.scala:24), which has no missing parents
21/10/14 23:47:25 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 10.1 KiB, free 1048.7 MiB)
21/10/14 23:47:25 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 1048.7 MiB)
21/10/14 23:47:25 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:56386 (size: 5.3 KiB, free: 1048.8 MiB)
21/10/14 23:47:25 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1383
21/10/14 23:47:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[87] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/14 23:47:25 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0
21/10/14 23:47:25 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 16) (localhost, executor driver, partition 0, PROCESS_LOCAL, 4626 bytes) taskResourceAssignments Map()
21/10/14 23:47:25 INFO Executor: Running task 0.0 in stage 26.0 (TID 16)
21/10/14 23:47:25 INFO Executor: Finished task 0.0 in stage 26.0 (TID 16). 1833 bytes result sent to driver
21/10/14 23:47:25 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 16) in 7 ms on localhost (executor driver) (1/1)
21/10/14 23:47:25 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
21/10/14 23:47:25 INFO DAGScheduler: ShuffleMapStage 26 (count at utils.scala:24) finished in 0.011 s
21/10/14 23:47:25 INFO DAGScheduler: looking for newly runnable stages
21/10/14 23:47:25 INFO DAGScheduler: running: Set()
21/10/14 23:47:25 INFO DAGScheduler: waiting: Set(ResultStage 27)
21/10/14 23:47:25 INFO DAGScheduler: failed: Set()
21/10/14 23:47:25 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[90] at count at utils.scala:24), which has no missing parents
21/10/14 23:47:25 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 10.1 KiB, free 1048.7 MiB)
21/10/14 23:47:25 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 1048.7 MiB)
21/10/14 23:47:25 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:56386 (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:47:25 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1383
21/10/14 23:47:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[90] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/14 23:47:25 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
21/10/14 23:47:25 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 17) (localhost, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/10/14 23:47:25 INFO Executor: Running task 0.0 in stage 27.0 (TID 17)
21/10/14 23:47:25 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/10/14 23:47:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/10/14 23:47:25 INFO Executor: Finished task 0.0 in stage 27.0 (TID 17). 2648 bytes result sent to driver
21/10/14 23:47:25 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 17) in 4 ms on localhost (executor driver) (1/1)
21/10/14 23:47:25 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
21/10/14 23:47:25 INFO DAGScheduler: ResultStage 27 (count at utils.scala:24) finished in 0.007 s
21/10/14 23:47:25 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
21/10/14 23:47:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
21/10/14 23:47:25 INFO DAGScheduler: Job 14 finished: count at utils.scala:24, took 0.021108 s
21/10/14 23:50:20 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:50:20 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:50:20 INFO HiveMetaStore: 0: get_database: default
21/10/14 23:50:20 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_database: default	
21/10/14 23:50:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/10/14 23:50:20 INFO audit: ugi=michael	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/10/14 23:50:20 INFO CodeGenerator: Code generated in 6.00613 ms
21/10/14 23:50:20 INFO CodeGenerator: Code generated in 5.265569 ms
21/10/14 23:50:20 INFO SparkContext: Starting job: count at utils.scala:24
21/10/14 23:50:20 INFO DAGScheduler: Registering RDD 93 (count at utils.scala:24) as input to shuffle 13
21/10/14 23:50:20 INFO DAGScheduler: Got job 15 (count at utils.scala:24) with 1 output partitions
21/10/14 23:50:20 INFO DAGScheduler: Final stage: ResultStage 29 (count at utils.scala:24)
21/10/14 23:50:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
21/10/14 23:50:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 28)
21/10/14 23:50:20 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[93] at count at utils.scala:24), which has no missing parents
21/10/14 23:50:20 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 10.1 KiB, free 1048.7 MiB)
21/10/14 23:50:20 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 1048.7 MiB)
21/10/14 23:50:20 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:56386 (size: 5.3 KiB, free: 1048.8 MiB)
21/10/14 23:50:20 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1383
21/10/14 23:50:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[93] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/14 23:50:20 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
21/10/14 23:50:20 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 18) (localhost, executor driver, partition 0, PROCESS_LOCAL, 4626 bytes) taskResourceAssignments Map()
21/10/14 23:50:20 INFO Executor: Running task 0.0 in stage 28.0 (TID 18)
21/10/14 23:50:20 INFO Executor: Finished task 0.0 in stage 28.0 (TID 18). 1833 bytes result sent to driver
21/10/14 23:50:20 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 18) in 9 ms on localhost (executor driver) (1/1)
21/10/14 23:50:20 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
21/10/14 23:50:20 INFO DAGScheduler: ShuffleMapStage 28 (count at utils.scala:24) finished in 0.016 s
21/10/14 23:50:20 INFO DAGScheduler: looking for newly runnable stages
21/10/14 23:50:20 INFO DAGScheduler: running: Set()
21/10/14 23:50:20 INFO DAGScheduler: waiting: Set(ResultStage 29)
21/10/14 23:50:20 INFO DAGScheduler: failed: Set()
21/10/14 23:50:20 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[96] at count at utils.scala:24), which has no missing parents
21/10/14 23:50:20 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 10.1 KiB, free 1048.7 MiB)
21/10/14 23:50:20 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 1048.7 MiB)
21/10/14 23:50:20 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:56386 (size: 5.0 KiB, free: 1048.8 MiB)
21/10/14 23:50:20 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1383
21/10/14 23:50:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[96] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/14 23:50:20 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
21/10/14 23:50:20 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 19) (localhost, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/10/14 23:50:20 INFO Executor: Running task 0.0 in stage 29.0 (TID 19)
21/10/14 23:50:20 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/10/14 23:50:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/10/14 23:50:20 INFO Executor: Finished task 0.0 in stage 29.0 (TID 19). 2648 bytes result sent to driver
21/10/14 23:50:20 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 19) in 7 ms on localhost (executor driver) (1/1)
21/10/14 23:50:20 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
21/10/14 23:50:20 INFO DAGScheduler: ResultStage 29 (count at utils.scala:24) finished in 0.013 s
21/10/14 23:50:20 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
21/10/14 23:50:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
21/10/14 23:50:20 INFO DAGScheduler: Job 15 finished: count at utils.scala:24, took 0.034189 s
21/10/14 23:50:28 INFO SparkContext: Starting job: collect at utils.scala:26
21/10/14 23:50:28 INFO DAGScheduler: Got job 16 (collect at utils.scala:26) with 1 output partitions
21/10/14 23:50:28 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:26)
21/10/14 23:50:28 INFO DAGScheduler: Parents of final stage: List()
21/10/14 23:50:28 INFO DAGScheduler: Missing parents: List()
21/10/14 23:50:28 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[103] at collect at utils.scala:26), which has no missing parents
21/10/14 23:50:28 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 23.1 KiB, free 1048.7 MiB)
21/10/14 23:50:28 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 8.4 KiB, free 1048.7 MiB)
21/10/14 23:50:28 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:56386 (size: 8.4 KiB, free: 1048.8 MiB)
21/10/14 23:50:28 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1383
21/10/14 23:50:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[103] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
21/10/14 23:50:28 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
21/10/14 23:50:28 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 20) (localhost, executor driver, partition 0, PROCESS_LOCAL, 236172 bytes) taskResourceAssignments Map()
21/10/14 23:50:28 INFO Executor: Running task 0.0 in stage 30.0 (TID 20)
21/10/14 23:50:28 INFO CodeGenerator: Code generated in 36.23447 ms
21/10/14 23:50:28 INFO MemoryStore: Block rdd_99_0 stored as values in memory (estimated size 236.6 KiB, free 1048.4 MiB)
21/10/14 23:50:28 INFO BlockManagerInfo: Added rdd_99_0 in memory on localhost:56386 (size: 236.6 KiB, free: 1048.5 MiB)
21/10/14 23:50:28 INFO CodeGenerator: Code generated in 3.594016 ms
21/10/14 23:50:28 INFO CodeGenerator: Code generated in 36.469028 ms
21/10/14 23:50:28 INFO Executor: 1 block locks were not released by task 0.0 in stage 30.0 (TID 20)
[rdd_99_0]
21/10/14 23:50:28 INFO Executor: Finished task 0.0 in stage 30.0 (TID 20). 9691 bytes result sent to driver
21/10/14 23:50:28 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 20) in 184 ms on localhost (executor driver) (1/1)
21/10/14 23:50:28 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
21/10/14 23:50:28 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:26) finished in 0.202 s
21/10/14 23:50:28 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
21/10/14 23:50:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
21/10/14 23:50:28 INFO DAGScheduler: Job 16 finished: collect at utils.scala:26, took 0.205482 s
21/10/14 23:50:28 INFO CodeGenerator: Code generated in 24.510747 ms
21/10/14 23:50:28 INFO CodeGenerator: Code generated in 6.727759 ms
21/10/14 23:50:28 INFO CodeGenerator: Code generated in 3.434752 ms
21/10/14 23:50:28 INFO SparkContext: Starting job: count at utils.scala:24
21/10/14 23:50:28 INFO DAGScheduler: Registering RDD 108 (count at utils.scala:24) as input to shuffle 14
21/10/14 23:50:28 INFO DAGScheduler: Got job 17 (count at utils.scala:24) with 1 output partitions
21/10/14 23:50:28 INFO DAGScheduler: Final stage: ResultStage 32 (count at utils.scala:24)
21/10/14 23:50:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
21/10/14 23:50:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
21/10/14 23:50:28 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[108] at count at utils.scala:24), which has no missing parents
21/10/14 23:50:28 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 24.9 KiB, free 1048.4 MiB)
21/10/14 23:50:28 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 9.3 KiB, free 1048.4 MiB)
21/10/14 23:50:28 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on localhost:56386 (size: 9.3 KiB, free: 1048.5 MiB)
21/10/14 23:50:28 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1383
21/10/14 23:50:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[108] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/14 23:50:28 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
21/10/14 23:50:28 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 21) (localhost, executor driver, partition 0, PROCESS_LOCAL, 236161 bytes) taskResourceAssignments Map()
21/10/14 23:50:28 INFO Executor: Running task 0.0 in stage 31.0 (TID 21)
21/10/14 23:50:28 INFO BlockManager: Found block rdd_99_0 locally
21/10/14 23:50:28 INFO CodeGenerator: Code generated in 7.062267 ms
21/10/14 23:50:28 INFO Executor: 1 block locks were not released by task 0.0 in stage 31.0 (TID 21)
[rdd_99_0]
21/10/14 23:50:28 INFO Executor: Finished task 0.0 in stage 31.0 (TID 21). 1920 bytes result sent to driver
21/10/14 23:50:28 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 21) in 17 ms on localhost (executor driver) (1/1)
21/10/14 23:50:28 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
21/10/14 23:50:28 INFO DAGScheduler: ShuffleMapStage 31 (count at utils.scala:24) finished in 0.024 s
21/10/14 23:50:28 INFO DAGScheduler: looking for newly runnable stages
21/10/14 23:50:28 INFO DAGScheduler: running: Set()
21/10/14 23:50:28 INFO DAGScheduler: waiting: Set(ResultStage 32)
21/10/14 23:50:28 INFO DAGScheduler: failed: Set()
21/10/14 23:50:28 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[111] at count at utils.scala:24), which has no missing parents
21/10/14 23:50:28 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 11.5 KiB, free 1048.4 MiB)
21/10/14 23:50:28 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 1048.4 MiB)
21/10/14 23:50:28 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on localhost:56386 (size: 5.3 KiB, free: 1048.5 MiB)
21/10/14 23:50:28 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1383
21/10/14 23:50:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[111] at count at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/10/14 23:50:28 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
21/10/14 23:50:28 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 22) (localhost, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/10/14 23:50:28 INFO Executor: Running task 0.0 in stage 32.0 (TID 22)
21/10/14 23:50:28 INFO ShuffleBlockFetcherIterator: Getting 1 (54.0 B) non-empty blocks including 1 (54.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/10/14 23:50:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/10/14 23:50:28 INFO Executor: Finished task 0.0 in stage 32.0 (TID 22). 2471 bytes result sent to driver
21/10/14 23:50:28 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 22) in 6 ms on localhost (executor driver) (1/1)
21/10/14 23:50:28 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
21/10/14 23:50:28 INFO DAGScheduler: ResultStage 32 (count at utils.scala:24) finished in 0.010 s
21/10/14 23:50:28 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
21/10/14 23:50:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
21/10/14 23:50:28 INFO DAGScheduler: Job 17 finished: count at utils.scala:24, took 0.038191 s
